{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import standard libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.metrics.pairwise import linear_kernel, cosine_similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie=pd.read_csv('rotten_tomatoes_movies.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rotten_tomatoes_link                   0\n",
       "movie_title                            0\n",
       "movie_info                           321\n",
       "critics_consensus                   8578\n",
       "content_rating                         0\n",
       "genres                                19\n",
       "directors                            194\n",
       "authors                             1542\n",
       "actors                               352\n",
       "original_release_date               1166\n",
       "streaming_release_date               384\n",
       "runtime                              314\n",
       "production_company                   499\n",
       "tomatometer_status                    44\n",
       "tomatometer_rating                    44\n",
       "tomatometer_count                     44\n",
       "audience_status                      448\n",
       "audience_rating                      296\n",
       "audience_count                       297\n",
       "tomatometer_top_critics_count          0\n",
       "tomatometer_fresh_critics_count        0\n",
       "tomatometer_rotten_critics_count       0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "movie.isna().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>review_type</th>\n",
       "      <th>tagged</th>\n",
       "      <th>lemmatized</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>[NOUN, NOUN, VERB, ADJ, NOUN, ADJ, ADJ, NOUN, ...</td>\n",
       "      <td>[fantasy, adventure, fuse, greek, mythology, c...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>[PROPN, NOUN, NOUN, NOUN, NOUN, NOUN, NOUN, NO...</td>\n",
       "      <td>[uma, thurman, medusa, gorgon, coiffure, writh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>[ADJ, NOUN, NOUN, VERB, ADJ, NOUN, NOUN, NOUN,...</td>\n",
       "      <td>[top, notch, cast, dazzle, special, effect, ti...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Fresh</td>\n",
       "      <td>[SCONJ, NOUN, VERB, ADP, NOUN, NOUN, ADV, VERB...</td>\n",
       "      <td>[whether, audience, get, behind, lightning, th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>m/0814255</td>\n",
       "      <td>Rotten</td>\n",
       "      <td>[ADV, VERB, NOUN, NOUN, ADJ, NOUN, NOUN, NOUN,...</td>\n",
       "      <td>[really, lack, lightning, thief, genuine, sens...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   index rotten_tomatoes_link review_type  \\\n",
       "0      0            m/0814255       Fresh   \n",
       "1      1            m/0814255       Fresh   \n",
       "2      2            m/0814255       Fresh   \n",
       "3      3            m/0814255       Fresh   \n",
       "4      4            m/0814255      Rotten   \n",
       "\n",
       "                                              tagged  \\\n",
       "0  [NOUN, NOUN, VERB, ADJ, NOUN, ADJ, ADJ, NOUN, ...   \n",
       "1  [PROPN, NOUN, NOUN, NOUN, NOUN, NOUN, NOUN, NO...   \n",
       "2  [ADJ, NOUN, NOUN, VERB, ADJ, NOUN, NOUN, NOUN,...   \n",
       "3  [SCONJ, NOUN, VERB, ADP, NOUN, NOUN, ADV, VERB...   \n",
       "4  [ADV, VERB, NOUN, NOUN, ADJ, NOUN, NOUN, NOUN,...   \n",
       "\n",
       "                                          lemmatized  \n",
       "0  [fantasy, adventure, fuse, greek, mythology, c...  \n",
       "1  [uma, thurman, medusa, gorgon, coiffure, writh...  \n",
       "2  [top, notch, cast, dazzle, special, effect, ti...  \n",
       "3  [whether, audience, get, behind, lightning, th...  \n",
       "4  [really, lack, lightning, thief, genuine, sens...  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# read in data (the pre-processed version)\n",
    "critic_reviews_processed = pd.DataFrame()\n",
    "for i in range(5):\n",
    "  # when saving as csv, the lists get turned into strings so we convert back\n",
    "  temp =  pd.read_csv(\"critic_reviews_processed_{}.csv\".format(i), converters={'tagged': eval,'lemmatized': eval})\n",
    "  critic_reviews_processed = pd.concat([critic_reviews_processed, temp])\n",
    "\n",
    "# look at some data to verify the load was successful\n",
    "critic_reviews_processed.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "949181"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of reviews\n",
    "len(critic_reviews_processed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17695"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of movies\n",
    "critic_reviews_processed.rotten_tomatoes_link.nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>review_count</th>\n",
       "      <th>freshness</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/+_one_2019</td>\n",
       "      <td>[get, strength, fundamental, lead, crackle, ch...</td>\n",
       "      <td>63</td>\n",
       "      <td>88.888889</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/+h</td>\n",
       "      <td>[ultimately, plush, exceed, limited, expectati...</td>\n",
       "      <td>6</td>\n",
       "      <td>33.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/-_man</td>\n",
       "      <td>[owen, wilson, look, reassure, depend, much, t...</td>\n",
       "      <td>11</td>\n",
       "      <td>63.636364</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/-cule_valley_of_the_lost_ants</td>\n",
       "      <td>[dialogue, free, bug, saga, carry, along, bril...</td>\n",
       "      <td>10</td>\n",
       "      <td>90.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>[fantasy, adventure, fuse, greek, mythology, c...</td>\n",
       "      <td>148</td>\n",
       "      <td>49.324324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "              rotten_tomatoes_link  \\\n",
       "0                     m/+_one_2019   \n",
       "1                             m/+h   \n",
       "2                          m/-_man   \n",
       "3  m/-cule_valley_of_the_lost_ants   \n",
       "4                        m/0814255   \n",
       "\n",
       "                                          lemmatized  review_count  freshness  \n",
       "0  [get, strength, fundamental, lead, crackle, ch...            63  88.888889  \n",
       "1  [ultimately, plush, exceed, limited, expectati...             6  33.333333  \n",
       "2  [owen, wilson, look, reassure, depend, much, t...            11  63.636364  \n",
       "3  [dialogue, free, bug, saga, carry, along, bril...            10  90.000000  \n",
       "4  [fantasy, adventure, fuse, greek, mythology, c...           148  49.324324  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# group by movie/review_type and concatenate each review\n",
    "# LDA performs better on longer documents (need proof/reference of claim!)\n",
    "\n",
    "# df = critic_reviews_processed.groupby(['rotten_tomatoes_link']).agg({'lemmatized': 'sum'}).reset_index()\n",
    "# df.head()\n",
    "\n",
    "df = critic_reviews_processed.groupby(['rotten_tomatoes_link','review_type']).agg({'lemmatized':'sum','tagged':'count'}).reset_index()\n",
    "df['prop'] = df.groupby(['rotten_tomatoes_link'])['tagged'].apply(lambda x:100 * x / float(x.sum()))\n",
    "df_fresh = df[df['review_type']=='Fresh'][['rotten_tomatoes_link','prop']]\n",
    "df = df.groupby(['rotten_tomatoes_link']).agg({'lemmatized':'sum','tagged':'sum'}).reset_index()\n",
    "df = df.merge(df_fresh, how='left',on='rotten_tomatoes_link')\n",
    "df = df.rename(columns={'tagged':'review_count','prop':'freshness'})\n",
    "df = df.fillna(value={'freshness':50})\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17695"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# count number of rows\n",
    "len(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# count number of words per document\n",
    "df['words'] = df['lemmatized'].apply(lambda x: len(x))\n",
    "# distribution of length of documents\n",
    "#fig = plt.figure(figsize=(12, 6), dpi=100)\n",
    "#ax = fig.add_subplot(1,1,1)\n",
    "#sns.histplot(data=df,x='words',ax=ax)\n",
    "#ax.set_xlabel('Number of words per document')\n",
    "#plt.tight_layout()\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(656.0611472167279, 280.0)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# average number of words\n",
    "df['words'].mean(), df['words'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3975"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# how many movies have less than 100 words?\n",
    "# NEED TO JUSTIFY THIS NUMBER!\n",
    "len(df[df['words']<100])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(686.8535356528955, 306.0)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove them from the training dataset\n",
    "df = df[df['words']>=40]\n",
    "df = df.reset_index(drop=True)\n",
    "# average number of words now\n",
    "df['words'].mean(), df['words'].median()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>review_count</th>\n",
       "      <th>freshness</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>m/+_one_2019</td>\n",
       "      <td>[get, strength, fundamental, lead, crackle, ch...</td>\n",
       "      <td>63</td>\n",
       "      <td>88.888889</td>\n",
       "      <td>852</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>m/+h</td>\n",
       "      <td>[ultimately, plush, exceed, limited, expectati...</td>\n",
       "      <td>6</td>\n",
       "      <td>33.333333</td>\n",
       "      <td>71</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>m/-_man</td>\n",
       "      <td>[owen, wilson, look, reassure, depend, much, t...</td>\n",
       "      <td>11</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>111</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>m/-cule_valley_of_the_lost_ants</td>\n",
       "      <td>[dialogue, free, bug, saga, carry, along, bril...</td>\n",
       "      <td>10</td>\n",
       "      <td>90.000000</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>m/0814255</td>\n",
       "      <td>[fantasy, adventure, fuse, greek, mythology, c...</td>\n",
       "      <td>148</td>\n",
       "      <td>49.324324</td>\n",
       "      <td>1868</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16866</th>\n",
       "      <td>m/zoot_suit</td>\n",
       "      <td>[interesting, full, review, spanish, curious, ...</td>\n",
       "      <td>6</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>65</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16867</th>\n",
       "      <td>m/zootopia</td>\n",
       "      <td>[variety, cute, occasionally, slightly, scary,...</td>\n",
       "      <td>291</td>\n",
       "      <td>97.594502</td>\n",
       "      <td>3816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16868</th>\n",
       "      <td>m/zorba_the_greek</td>\n",
       "      <td>[zorba, greek, motion, picture, right, every, ...</td>\n",
       "      <td>7</td>\n",
       "      <td>71.428571</td>\n",
       "      <td>79</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16869</th>\n",
       "      <td>m/zulu</td>\n",
       "      <td>[amazing, film, devastatingly, accurate, depic...</td>\n",
       "      <td>17</td>\n",
       "      <td>94.117647</td>\n",
       "      <td>199</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16870</th>\n",
       "      <td>m/zulu_dawn</td>\n",
       "      <td>[see, today, startling, indictment, british, i...</td>\n",
       "      <td>4</td>\n",
       "      <td>50.000000</td>\n",
       "      <td>63</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16871 rows Ã— 5 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                  rotten_tomatoes_link  \\\n",
       "0                         m/+_one_2019   \n",
       "1                                 m/+h   \n",
       "2                              m/-_man   \n",
       "3      m/-cule_valley_of_the_lost_ants   \n",
       "4                            m/0814255   \n",
       "...                                ...   \n",
       "16866                      m/zoot_suit   \n",
       "16867                       m/zootopia   \n",
       "16868                m/zorba_the_greek   \n",
       "16869                           m/zulu   \n",
       "16870                      m/zulu_dawn   \n",
       "\n",
       "                                              lemmatized  review_count  \\\n",
       "0      [get, strength, fundamental, lead, crackle, ch...            63   \n",
       "1      [ultimately, plush, exceed, limited, expectati...             6   \n",
       "2      [owen, wilson, look, reassure, depend, much, t...            11   \n",
       "3      [dialogue, free, bug, saga, carry, along, bril...            10   \n",
       "4      [fantasy, adventure, fuse, greek, mythology, c...           148   \n",
       "...                                                  ...           ...   \n",
       "16866  [interesting, full, review, spanish, curious, ...             6   \n",
       "16867  [variety, cute, occasionally, slightly, scary,...           291   \n",
       "16868  [zorba, greek, motion, picture, right, every, ...             7   \n",
       "16869  [amazing, film, devastatingly, accurate, depic...            17   \n",
       "16870  [see, today, startling, indictment, british, i...             4   \n",
       "\n",
       "       freshness  words  \n",
       "0      88.888889    852  \n",
       "1      33.333333     71  \n",
       "2      63.636364    111  \n",
       "3      90.000000    120  \n",
       "4      49.324324   1868  \n",
       "...          ...    ...  \n",
       "16866  50.000000     65  \n",
       "16867  97.594502   3816  \n",
       "16868  71.428571     79  \n",
       "16869  94.117647    199  \n",
       "16870  50.000000     63  \n",
       "\n",
       "[16871 rows x 5 columns]"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Movie description and rating only RS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "for column in movie.columns:\n",
    "    if movie[column].dtype=='O':\n",
    "        movie[column].fillna('',inplace=True)\n",
    "    else:\n",
    "        movie[column].fillna(0, inplace=True)\n",
    "#Only kept top 5 important actors\n",
    "movie['actors']=movie['actors'].apply(lambda x:','.join(str(x).split(',')[0:5]))\n",
    "#Map the content rating by numbers- 0: for everyone, 5: adult only\n",
    "rating={'NR':0, 'G':1, 'PG':2,'PG-13':3, 'R':4, 'NC17':5}\n",
    "movie['content_rating']=movie['content_rating'].map(rating)\n",
    "movie['year']=movie['original_release_date'].apply(lambda x: str(x).split('-')[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Some movie misses a year so I replace the missing year by the streaming year\n",
    "\n",
    "stream_year=movie['streaming_release_date'].apply(lambda x: str(x).split('-')[0])\n",
    "movie['year']=movie['year'].replace('',stream_year[movie['year']==''])\n",
    "#The rest I replace by 1956, which is the mean of year\n",
    "movie['year']=movie['year'].replace('',1956)\n",
    "movie['year']=movie['year'].astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the weighted rating based on IMDB formula\n",
    "def weighted_rating(x, m, C):\n",
    "    v = x['audience_count']\n",
    "    R = x['audience_rating']\n",
    "    return (v/(v+m) * R) + (m/(m+v) * C)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_recommendations(title, cosine_sim):\n",
    "    # Get the index of the movie that matches the title\n",
    "    \n",
    "    #Find the most possible movie title if the input title name is slightly wrong\n",
    "    movie_list = df_new[df_new['movie_title'].str.contains(title)]\n",
    "    if len(movie_list):\n",
    "        #In case of similar movie title like 'Iron Man' and 'Iron Man 2'\n",
    "        if any(movie_list['movie_title']==title):\n",
    "            movie_title=title\n",
    "        else:\n",
    "           # Pick the one with the highest audience rating\n",
    "            movie_title=movie_list.sort_values(by=['audience_rating'], ascending=False)['movie_title'].iloc[0]\n",
    "        \n",
    "        print('Selected movie:',movie_title)\n",
    "    \n",
    "        #Some movies are duplicated such as Frozen has two version.\n",
    "        #Pick the one with higher audience rating\n",
    "        idx = indices[movie_title]\n",
    "        if np.isscalar(idx)==False:\n",
    "            idx=df_new.iloc[idx].sort_values(by=['audience_rating'], ascending=False).index[0]\n",
    "        \n",
    "        #Define the target movie content rating\n",
    "        movie_content_rating=df_new.iloc[idx]['content_rating']\n",
    "        \n",
    "        movie_year=df_new.iloc[idx]['year']\n",
    "        # Get the pairwsie similarity scores of all movies with that movie\n",
    "        sim_scores = list(enumerate(cosine_sim[idx]))\n",
    "        \n",
    "        # Sort the movies based on the similarity scores\n",
    "        sim_scores = sorted(sim_scores, key=lambda x: x[1], reverse=True)\n",
    "\n",
    "        # Get the scores of the 30 most similar movies\n",
    "        sim_scores = sim_scores[1:30]\n",
    "        \n",
    "        # Get the movie indices\n",
    "        movie_indices = [i[0] for i in sim_scores]\n",
    "        \n",
    "        #Calculate the weighted rating inside the list\n",
    "        #Some movies are highly rated due to few audience counts\n",
    "        #100 score with only 10 ppl rated does not mean a good movie\n",
    "        selected_movies=df_new.iloc[movie_indices]\n",
    "        audience_counts = selected_movies[selected_movies['audience_count'].notnull()]['audience_count'].astype('int')\n",
    "        m = audience_counts.quantile(0.5)\n",
    "        \n",
    "        C=selected_movies['audience_rating'].mean()\n",
    "        wr=selected_movies.apply(lambda x: weighted_rating(x,m,C), axis=1)\n",
    "        \n",
    "        df=pd.DataFrame(df_new[['movie_title','content_rating','year','audience_rating','audience_count']].iloc[movie_indices])\n",
    "\n",
    "        df['Score']=[x[1] for x in sim_scores]\n",
    "        df['wr']=wr\n",
    "        #Product for similarity and rating so priortise to recommend high similarity and high rating movies\n",
    "        df['mix_score']=df['audience_rating']*df['Score']\n",
    "        \n",
    "        #df['mix_score']=df['audience_rating']*df['Score']\n",
    "        #Set the limit for number of audience count\n",
    "        #At least higher than 50% quantile of the audience count in the whole document\n",
    "        count_bound=movie['audience_count'].quantile(0.5)\n",
    "        #Remove movie that is over the target movie content rating and with too few audience\n",
    "        #ranked by the mix score\n",
    "        df=df[(df['content_rating']<=movie_content_rating) & (df['audience_count']>count_bound) &(df['year']>movie_year-10)]\n",
    "        df=df.sort_values('mix_score', ascending=False)\n",
    "        \n",
    "        # Return the top 10 most similar movies\n",
    "        return df[['movie_title','year','Score', 'wr','audience_rating', 'audience_count']].head(10)\n",
    "\n",
    "    else:\n",
    "        print('This movie does not exist. Please check your input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie['all_feature']=movie['movie_info']+movie['genres']+movie['actors']+movie['directors']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "chop_movie=movie.drop(['tomatometer_status','streaming_release_date','tomatometer_status', 'tomatometer_rating',\n",
    "       'tomatometer_count','tomatometer_top_critics_count',\n",
    "       'tomatometer_fresh_critics_count', 'tomatometer_rotten_critics_count','audience_status','runtime' ], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_new=pd.merge(df, chop_movie, how='inner', on=['rotten_tomatoes_link'])\n",
    "indices = pd.Series(df_new.index, index=df_new['movie_title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf = TfidfVectorizer(analyzer='word',ngram_range=(1, 2),min_df=0, stop_words='english')\n",
    "tfidf_matrix_all = tf.fit_transform(df_new['all_feature'])\n",
    "cosine_sim_all = linear_kernel(tfidf_matrix_all, tfidf_matrix_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Iron Man\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>wr</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.259877</td>\n",
       "      <td>70.190409</td>\n",
       "      <td>71.0</td>\n",
       "      <td>480879.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>Iron Man 3</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.191389</td>\n",
       "      <td>76.310244</td>\n",
       "      <td>78.0</td>\n",
       "      <td>485128.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.141748</td>\n",
       "      <td>79.406367</td>\n",
       "      <td>83.0</td>\n",
       "      <td>288708.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.106612</td>\n",
       "      <td>77.327586</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>Spider-Man: Homecoming</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.101618</td>\n",
       "      <td>78.195561</td>\n",
       "      <td>87.0</td>\n",
       "      <td>108167.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.087815</td>\n",
       "      <td>82.164485</td>\n",
       "      <td>89.0</td>\n",
       "      <td>180162.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>2018</td>\n",
       "      <td>0.076309</td>\n",
       "      <td>76.642157</td>\n",
       "      <td>91.0</td>\n",
       "      <td>58720.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12544</th>\n",
       "      <td>Sherlock Holmes: A Game of Shadows</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.077091</td>\n",
       "      <td>73.364507</td>\n",
       "      <td>77.0</td>\n",
       "      <td>168495.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5321</th>\n",
       "      <td>Dolittle</td>\n",
       "      <td>2020</td>\n",
       "      <td>0.073346</td>\n",
       "      <td>66.252540</td>\n",
       "      <td>76.0</td>\n",
       "      <td>11526.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12846</th>\n",
       "      <td>The Soloist</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.074162</td>\n",
       "      <td>57.824312</td>\n",
       "      <td>56.0</td>\n",
       "      <td>263355.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              movie_title  year     Score         wr  \\\n",
       "8051                           Iron Man 2  2010  0.259877  70.190409   \n",
       "8052                           Iron Man 3  2013  0.191389  76.310244   \n",
       "2873              Avengers: Age of Ultron  2015  0.141748  79.406367   \n",
       "2874                    Avengers: Endgame  2019  0.106612  77.327586   \n",
       "13002              Spider-Man: Homecoming  2017  0.101618  78.195561   \n",
       "4069           Captain America: Civil War  2016  0.087815  82.164485   \n",
       "2875               Avengers: Infinity War  2018  0.076309  76.642157   \n",
       "12544  Sherlock Holmes: A Game of Shadows  2011  0.077091  73.364507   \n",
       "5321                             Dolittle  2020  0.073346  66.252540   \n",
       "12846                         The Soloist  2009  0.074162  57.824312   \n",
       "\n",
       "       audience_rating  audience_count  \n",
       "8051              71.0        480879.0  \n",
       "8052              78.0        485128.0  \n",
       "2873              83.0        288708.0  \n",
       "2874              90.0         70334.0  \n",
       "13002             87.0        108167.0  \n",
       "4069              89.0        180162.0  \n",
       "2875              91.0         58720.0  \n",
       "12544             77.0        168495.0  \n",
       "5321              76.0         11526.0  \n",
       "12846             56.0        263355.0  "
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Iron Man', cosine_sim_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LDA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from gensim.models import LdaMulticore\n",
    "from gensim.models import Phrases\n",
    "from gensim.models.phrases import Phraser\n",
    "from gensim import corpora\n",
    "from gensim.models import TfidfModel\n",
    "\n",
    "# train model\n",
    "def train_lda(data, col):\n",
    "    \"\"\"\n",
    "    This function trains the lda model\n",
    "    We setup parameters like number of topics, the chunksize to use in Hoffman method\n",
    "    We also do 2 passes of the data since this is a small dataset, so we want the distributions to stabilize\n",
    "    \"\"\"\n",
    "    num_topics = 100\n",
    "    chunksize = 300\n",
    "    dictionary = corpora.Dictionary(data[col])\n",
    "    corpus = [dictionary.doc2bow(doc) for doc in data[col]]\n",
    "    t1 = time.time()\n",
    "    # low alpha means each document is only represented by a small number of topics, and vice versa\n",
    "    # low eta means each topic is only represented by a small number of words, and vice versa\n",
    "    lda = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                       alpha=1e-2, eta=0.5e-2, chunksize=chunksize, minimum_probability=0.0, passes=2)\n",
    "    t2 = time.time()\n",
    "    print(\"Time to train LDA model on \", len(data), \"articles: \", (t2-t1)/60, \"min\")\n",
    "    return dictionary,corpus,lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LDA model on  16871 articles:  2.352600045998891 min\n"
     ]
    }
   ],
   "source": [
    "# takes about ~2 mins\n",
    "dictionary,corpus,lda = train_lda(df,'lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from nltk.corpus import stopwords\n",
    "# stop_words = stopwords.words('english')\n",
    "# stop_words.extend(['movie','film'])\n",
    "\n",
    "# def remove_stopwords(texts,stop_words):\n",
    "#     full = []\n",
    "#     for doc in texts:\n",
    "#         row = []\n",
    "#         for token in doc:\n",
    "#             if token not in stop_words:\n",
    "#                 row.append(token)\n",
    "#         full.append(row)\n",
    "#     return full\n",
    "\n",
    "# df['lemmatized'] = remove_stopwords(df['lemmatized'].tolist(),stop_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Tuning lda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "num_topics = 100\n",
    "chunksize = 300\n",
    "dictionary = corpora.Dictionary(df['lemmatized'])\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['lemmatized']]\n",
    "lda = LdaMulticore(corpus=corpus, num_topics=num_topics, id2word=dictionary,\n",
    "                       alpha=1e-2, eta=0.5e-2, chunksize=chunksize, minimum_probability=0.0, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "coherence_model_lda = CoherenceModel(model=lda, texts=df['lemmatized'], dictionary=dictionary, coherence='c_v')\n",
    "coherence_lda = coherence_model_lda.get_coherence()\n",
    "print('\\nCoherence Score: ', coherence_lda)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models.coherencemodel import CoherenceModel\n",
    "import tqdm\n",
    "import gensim\n",
    "def compute_coherence_values(corpus, dictionary, k, a, b):\n",
    "    \n",
    "    lda_model = gensim.models.LdaMulticore(corpus=corpus,\n",
    "                                           id2word=dictionary,\n",
    "                                           num_topics=k, \n",
    "                                           chunksize=300,\n",
    "                                           minimum_probability=0.0,\n",
    "                                           passes=2,\n",
    "                                           alpha=a,\n",
    "                                           eta=b)\n",
    "    \n",
    "    coherence_model_lda = CoherenceModel(model=lda_model, texts=df['lemmatized'], dictionary=dictionary, coherence='c_v')\n",
    "    \n",
    "    return coherence_model_lda.get_coherence()\n",
    "\n",
    "# Alpha parameter\n",
    "alpha=np.geomspace(1e-10, 1, 10)\n",
    "# Beta parameter\n",
    "beta=np.geomspace(1e-10, 1, 10)\n",
    "\n",
    "model_results = {\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }\n",
    "\n",
    "# Can take a long time to run (around 6 hours )\n",
    "pbar = tqdm.tqdm(total=100)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "        # iterate through number of topics\n",
    "            # iterate through alpha values\n",
    "for a in alpha:\n",
    "                # iterare through beta values\n",
    "    for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=dictionary, \n",
    "                                                  k=100, a=a, b=b)\n",
    "                    # Save the model results\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(b)\n",
    "        model_results['Coherence'].append(cv)\n",
    "                    \n",
    "        pbar.update(1)\n",
    "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tqdm\n",
    "import gensim\n",
    "\n",
    "# Alpha parameter\n",
    "alpha=np.geomspace(1e-10, 1, 10)\n",
    "# Beta parameter\n",
    "beta=np.geomspace(1e-10, 1, 10)\n",
    "\n",
    "model_results = {\n",
    "                 'Alpha': [],\n",
    "                 'Beta': [],\n",
    "                 'Coherence': []\n",
    "                }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Can take a long time to run (around 6 hours )\n",
    "pbar = tqdm.tqdm(total=100)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "        # iterate through number of topics\n",
    "            # iterate through alpha values\n",
    "for a in alpha:\n",
    "                # iterare through beta values\n",
    "    for b in beta:\n",
    "                    # get the coherence score for the given parameters\n",
    "        cv = compute_coherence_values(corpus=corpus, dictionary=dictionary, \n",
    "                                                  k=100, a=a, b=b)\n",
    "                    # Save the model results\n",
    "        model_results['Alpha'].append(a)\n",
    "        model_results['Beta'].append(b)\n",
    "        model_results['Coherence'].append(cv)\n",
    "                    \n",
    "        pbar.update(1)\n",
    "pd.DataFrame(model_results).to_csv('lda_tuning_results.csv', index=False)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tuning_result=pd.read_csv('lda_tuning_results.csv')\n",
    "tuning_result.sort_values(by=['Coherence'], ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus, num_topics=100, id2word=dictionary,\n",
    "                       alpha=4.641589e-04, eta=4.641589e-04, chunksize=300, minimum_probability=0.0, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_coherence_values(corpus, dictionary, 100,4.641589e-04,4.641589e-04)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "topic_number_test={'Topics':[], 'Coherence':[]}\n",
    "topic_range=range(25,151, 25)\n",
    "dictionary = corpora.Dictionary(df['lemmatized'])\n",
    "corpus = [dictionary.doc2bow(doc) for doc in df['lemmatized']]\n",
    "# Can take a long time to run\n",
    "pbar = tqdm.tqdm(total=6)\n",
    "    \n",
    "    # iterate through validation corpuses\n",
    "        # iterate through number of topics\n",
    "for k in topic_range:\n",
    "            # iterate through alpha values\n",
    "    cv = compute_coherence_values(corpus=corpus, dictionary=dictionary, \n",
    "                                                  k=k, a=0.01, b=0.01)\n",
    "                    # Save the model results\n",
    "                #model_results['Validation_Set'].append(corpus_title[i])\n",
    "    topic_number_test['Topics'].append(k)\n",
    "    topic_number_test['Coherence'].append(cv)\n",
    "                    \n",
    "    pbar.update(1)\n",
    "pd.DataFrame(topic_number_test)\n",
    "pbar.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyLDAvis.gensim_models as gensimvis\n",
    "import pickle \n",
    "import pyLDAvis\n",
    "# Visualize the topics\n",
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = gensimvis.prepare(lda, corpus, dictionary)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "stop_words = stopwords.words('english')\n",
    "stop_words.extend(['movie','film','make', 'one'])\n",
    "\n",
    "def remove_stopwords(texts,stop_words):\n",
    "    full = []\n",
    "    for doc in texts:\n",
    "        row = []\n",
    "        for token in doc:\n",
    "            if token not in stop_words:\n",
    "                row.append(token)\n",
    "        full.append(row)\n",
    "    return full\n",
    "\n",
    "df['lemmatized'] = remove_stopwords(df['lemmatized'].tolist(),stop_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda = LdaMulticore(corpus=corpus, num_topics=25, id2word=dictionary,\n",
    "                       alpha=0.01, eta=0.01, chunksize=300, minimum_probability=0.0, passes=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_coherence_values(corpus, dictionary, 25,0.01,0.01)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pyLDAvis.enable_notebook()\n",
    "LDAvis_prepared = gensimvis.prepare(lda, corpus, dictionary)\n",
    "LDAvis_prepared"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Jensen-Shannon Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference: https://www.kaggle.com/ktattan/lda-and-document-similarity/data\n",
    "from scipy.spatial import distance\n",
    "def jensen_shannon(query, matrix):\n",
    "    \"\"\"\n",
    "    This function implements a Jensen-Shannon similarity\n",
    "    between the input query (an LDA topic distribution for a document)\n",
    "    and the entire corpus of topic distributions.\n",
    "    It returns an array of length M where M is the number of documents in the corpus\n",
    "    \"\"\"\n",
    "    sim = [distance.jensenshannon(data,query) for data in matrix]\n",
    "    return sim\n",
    "\n",
    "def get_most_similar_documents(query,matrix,k=10):\n",
    "    \"\"\"\n",
    "    This function implements the Jensen-Shannon distance above\n",
    "    and retruns the top k indices of the smallest jensen shannon distances\n",
    "    \"\"\"\n",
    "    sim = jensen_shannon(query,matrix) # list of jensen shannon distances\n",
    "\n",
    "    return np.argsort(sim)[:k] # the top k positional index of the smallest Jensen Shannon distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we need to use nested list comprehension here\n",
    "doc_topic_dist = np.array([[tup[1] for tup in lst] for lst in lda[corpus]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'idx' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-43-c22f66d6ce13>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mtest_bow\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdictionary\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdoc2bow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdf\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mloc\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0midx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m'lemmatized'\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      2\u001b[0m \u001b[0mtest_doc_distribution\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mtup\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;32mfor\u001b[0m \u001b[0mtup\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mlda\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_document_topics\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbow\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtest_bow\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'idx' is not defined"
     ]
    }
   ],
   "source": [
    "test_bow = dictionary.doc2bow(df.loc[idx]['lemmatized'])\n",
    "test_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=test_bow)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get bow for iron man 2\n",
    "test_bow = dictionary.doc2bow(df.loc[idx]['lemmatized'])\n",
    "test_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=test_bow)])\n",
    "# get similarity\n",
    "most_sim_ids = get_most_similar_documents(test_doc_distribution,doc_topic_dist)\n",
    "# best recommendations\n",
    "closest_ordering = {}\n",
    "for i,x in enumerate(most_sim_ids):\n",
    "    closest_ordering[x] = i\n",
    "closest_ordering = pd.DataFrame.from_dict(closest_ordering,orient='index')\n",
    "most_similar_df = df[df.index.isin(most_sim_ids)].reset_index()\n",
    "most_similar_df = df.merge(closest_ordering, how='right', left_index=True, right_index=True).drop(columns=0)\n",
    "most_similar_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Note:__ Much better results. Trying some other movies..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# turning it into a function:\n",
    "def recommend(movie_name,n=10):\n",
    "    # is it in the dataset?\n",
    "    try:\n",
    "        movie_index = df[df['rotten_tomatoes_link']=='m/{}'.format(movie_name)].index[0]\n",
    "        test_bow = dictionary.doc2bow(df.loc[movie_index]['lemmatized'])\n",
    "        test_doc_distribution = np.array([tup[1] for tup in lda.get_document_topics(bow=test_bow)])\n",
    "        # get top n most similar movies\n",
    "        most_sim_ids = get_most_similar_documents(test_doc_distribution,doc_topic_dist,k=n)\n",
    "        # best recommendations\n",
    "        closest_ordering = {}\n",
    "        for i,x in enumerate(most_sim_ids):\n",
    "            closest_ordering[x] = i\n",
    "        closest_ordering = pd.DataFrame.from_dict(closest_ordering,orient='index')\n",
    "        most_similar_df = df[df.index.isin(most_sim_ids)].reset_index()\n",
    "        most_similar_df = df.merge(closest_ordering, how='right', left_index=True, right_index=True).drop(columns=0)\n",
    "        return(most_similar_df)\n",
    "    except:\n",
    "        movie_index = df[df['rotten_tomatoes_link'].str.contains(movie_name)]['rotten_tomatoes_link'].tolist()\n",
    "        print('Movie name not recognised. Did you mean one of: ', movie_index, '?')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>review_count</th>\n",
       "      <th>freshness</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>16867</th>\n",
       "      <td>m/zootopia</td>\n",
       "      <td>[variety, cute, occasionally, slightly, scary,...</td>\n",
       "      <td>291</td>\n",
       "      <td>97.594502</td>\n",
       "      <td>3816</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6446</th>\n",
       "      <td>m/fritz_the_cat</td>\n",
       "      <td>[consider, un, cool, still, take, pleasure, vi...</td>\n",
       "      <td>15</td>\n",
       "      <td>46.666667</td>\n",
       "      <td>161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7929</th>\n",
       "      <td>m/indian_in_the_cupboard</td>\n",
       "      <td>[wonderful, adaptation, classic, book, inventi...</td>\n",
       "      <td>7</td>\n",
       "      <td>85.714286</td>\n",
       "      <td>77</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1048</th>\n",
       "      <td>m/1074108-101_dalmatians</td>\n",
       "      <td>[one, great, disney, classic, league, snow, wh...</td>\n",
       "      <td>14</td>\n",
       "      <td>42.857143</td>\n",
       "      <td>164</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15517</th>\n",
       "      <td>m/tinker_bell_and_the_lost_treasure</td>\n",
       "      <td>[imaginative, idea, exquisite, execution, key,...</td>\n",
       "      <td>5</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>81</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rotten_tomatoes_link  \\\n",
       "16867                           m/zootopia   \n",
       "6446                       m/fritz_the_cat   \n",
       "7929              m/indian_in_the_cupboard   \n",
       "1048              m/1074108-101_dalmatians   \n",
       "15517  m/tinker_bell_and_the_lost_treasure   \n",
       "\n",
       "                                              lemmatized  review_count  \\\n",
       "16867  [variety, cute, occasionally, slightly, scary,...           291   \n",
       "6446   [consider, un, cool, still, take, pleasure, vi...            15   \n",
       "7929   [wonderful, adaptation, classic, book, inventi...             7   \n",
       "1048   [one, great, disney, classic, league, snow, wh...            14   \n",
       "15517  [imaginative, idea, exquisite, execution, key,...             5   \n",
       "\n",
       "        freshness  words  \n",
       "16867   97.594502   3816  \n",
       "6446    46.666667    161  \n",
       "7929    85.714286     77  \n",
       "1048    42.857143    164  \n",
       "15517  100.000000     81  "
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('zootopia',5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>review_count</th>\n",
       "      <th>freshness</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>15525</th>\n",
       "      <td>m/titanic</td>\n",
       "      <td>[event, cold, april, night, detailed, reconstr...</td>\n",
       "      <td>191</td>\n",
       "      <td>89.005236</td>\n",
       "      <td>2174</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14837</th>\n",
       "      <td>m/the_overture</td>\n",
       "      <td>[film, probably, lose, effect, bring, western,...</td>\n",
       "      <td>5</td>\n",
       "      <td>60.000000</td>\n",
       "      <td>43</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6964</th>\n",
       "      <td>m/greystoke_the_legend_of_tarzan_lord_of_the_apes</td>\n",
       "      <td>[hugh, hudson, fashion, visually, resplendent,...</td>\n",
       "      <td>11</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>114</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1763</th>\n",
       "      <td>m/154</td>\n",
       "      <td>[quite, conventional, pack, powerful, punch, l...</td>\n",
       "      <td>7</td>\n",
       "      <td>57.142857</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6707</th>\n",
       "      <td>m/gladiator</td>\n",
       "      <td>[joyous, return, cinematic, epic, spectacle, h...</td>\n",
       "      <td>197</td>\n",
       "      <td>76.649746</td>\n",
       "      <td>2026</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    rotten_tomatoes_link  \\\n",
       "15525                                          m/titanic   \n",
       "14837                                     m/the_overture   \n",
       "6964   m/greystoke_the_legend_of_tarzan_lord_of_the_apes   \n",
       "1763                                               m/154   \n",
       "6707                                         m/gladiator   \n",
       "\n",
       "                                              lemmatized  review_count  \\\n",
       "15525  [event, cold, april, night, detailed, reconstr...           191   \n",
       "14837  [film, probably, lose, effect, bring, western,...             5   \n",
       "6964   [hugh, hudson, fashion, visually, resplendent,...            11   \n",
       "1763   [quite, conventional, pack, powerful, punch, l...             7   \n",
       "6707   [joyous, return, cinematic, epic, spectacle, h...           197   \n",
       "\n",
       "       freshness  words  \n",
       "15525  89.005236   2174  \n",
       "14837  60.000000     43  \n",
       "6964   81.818182    114  \n",
       "1763   57.142857    100  \n",
       "6707   76.649746   2026  "
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend('titanic',5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "\n",
    "- Add document size into the ranking\n",
    "    - a more prolific movie should get higher ranking\n",
    "    \n",
    "    \n",
    "- Add ratio of positive to negative reviews into the ranking\n",
    "    - a \"better\" movie should get higher ranking\n",
    "    \n",
    "    \n",
    "- Try a different similarity metric\n",
    "    - perhaps `cosine` similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Testing how to combine two scores- test case:Iron Man"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Testing on Iron Man\n",
    "idx = indices['Iron Man']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "#get the similarity score from cosine simlarity matrix\n",
    "sim_scores = list(enumerate(cosine_sim_all[idx]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "6\n"
     ]
    }
   ],
   "source": [
    "#Movie that not in the movie desciption \n",
    "movie_drop=[]\n",
    "for i in df['rotten_tomatoes_link']:\n",
    "    if i not in df_new['rotten_tomatoes_link'].unique():\n",
    "        movie_drop.append(i)\n",
    "print(len(movie_drop))\n",
    "# Create a new dataset with some movie dropped and merge with the movie description data\n",
    "df2=df[~df['rotten_tomatoes_link'].isin(movie_drop)]\n",
    "df_new=pd.merge(df2, chop_movie, how='inner', on=['rotten_tomatoes_link'])\n",
    "indices = pd.Series(df_new.index, index=df_new['movie_title']).drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train LDA model on  16865 articles:  2.301675339539846 min\n"
     ]
    }
   ],
   "source": [
    "#Rerun lda on the new review dataset\n",
    "dictionary2,corpus2,lda2 = train_lda(df2,'lemmatized')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc_topic_dist2 = np.array([[tup[1] for tup in lst] for lst in lda2[corpus2]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_bow2 = dictionary2.doc2bow(df_new.loc[idx]['lemmatized'])\n",
    "test_doc_distribution2 = np.array([tup[1] for tup in lda2.get_document_topics(bow=test_bow2)])\n",
    "# get top n most similar movies\n",
    "most_sim_ids2 = get_most_similar_documents(test_doc_distribution2,doc_topic_dist2,k=10)\n",
    "# best recommendations\n",
    "closest_ordering = {}\n",
    "for i,x in enumerate(most_sim_ids2):\n",
    "    closest_ordering[x] = i\n",
    "closest_ordering = pd.DataFrame.from_dict(closest_ordering,orient='index')\n",
    "most_similar_df = df_new[df_new.index.isin(most_sim_ids2)].reset_index()\n",
    "most_similar_df = df_new.merge(closest_ordering, how='right', left_index=True, right_index=True).drop(columns=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Getting the distance score\n",
    "lda_score=jensen_shannon(test_doc_distribution2,doc_topic_dist2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Checking if the shape lda_score matrix is same as cosine_similarity matrix\n",
    "len(lda_score)==len(cosine_sim_all[idx])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA_index</th>\n",
       "      <th>Distance</th>\n",
       "      <th>COS_index</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8051</td>\n",
       "      <td>0.219978</td>\n",
       "      <td>8051</td>\n",
       "      <td>0.259877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8052</td>\n",
       "      <td>0.225843</td>\n",
       "      <td>8052</td>\n",
       "      <td>0.191389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9656</td>\n",
       "      <td>0.243542</td>\n",
       "      <td>2873</td>\n",
       "      <td>0.141748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2873</td>\n",
       "      <td>0.276263</td>\n",
       "      <td>2874</td>\n",
       "      <td>0.106612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16720</td>\n",
       "      <td>0.309203</td>\n",
       "      <td>12680</td>\n",
       "      <td>0.106365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16859</th>\n",
       "      <td>121</td>\n",
       "      <td>0.832217</td>\n",
       "      <td>16854</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16860</th>\n",
       "      <td>10585</td>\n",
       "      <td>0.832234</td>\n",
       "      <td>16857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16861</th>\n",
       "      <td>6978</td>\n",
       "      <td>0.832237</td>\n",
       "      <td>16858</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16862</th>\n",
       "      <td>1862</td>\n",
       "      <td>0.832250</td>\n",
       "      <td>16860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16863</th>\n",
       "      <td>16301</td>\n",
       "      <td>0.832252</td>\n",
       "      <td>16863</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LDA_index  Distance  COS_index     Score\n",
       "0           8051  0.219978       8051  0.259877\n",
       "1           8052  0.225843       8052  0.191389\n",
       "2           9656  0.243542       2873  0.141748\n",
       "3           2873  0.276263       2874  0.106612\n",
       "4          16720  0.309203      12680  0.106365\n",
       "...          ...       ...        ...       ...\n",
       "16859        121  0.832217      16854  0.000000\n",
       "16860      10585  0.832234      16857  0.000000\n",
       "16861       6978  0.832237      16858  0.000000\n",
       "16862       1862  0.832250      16860  0.000000\n",
       "16863      16301  0.832252      16863  0.000000\n",
       "\n",
       "[16864 rows x 4 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Lower distance =better, while higher score= better--- Non-comparable\n",
    "lda_score_df=pd.DataFrame(sorted(list(enumerate(lda_score)), key=lambda x:x[1])[1:], columns=['LDA_index', 'Distance'])\n",
    "cos_score_df=pd.DataFrame(sorted(list(enumerate(cosine_sim_all[idx])), key=lambda x:x[1], reverse=True)[1:], columns=['COS_index','Score'])\n",
    "#Iron Man Score\n",
    "mix_df=pd.concat([lda_score_df, cos_score_df], axis=1)\n",
    "mix_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>LDA_index</th>\n",
       "      <th>Distance</th>\n",
       "      <th>COS_index</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8051</td>\n",
       "      <td>0.780022</td>\n",
       "      <td>8051</td>\n",
       "      <td>0.259877</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>8052</td>\n",
       "      <td>0.774157</td>\n",
       "      <td>8052</td>\n",
       "      <td>0.191389</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>9656</td>\n",
       "      <td>0.756458</td>\n",
       "      <td>2873</td>\n",
       "      <td>0.141748</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2873</td>\n",
       "      <td>0.723737</td>\n",
       "      <td>2874</td>\n",
       "      <td>0.106612</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>16720</td>\n",
       "      <td>0.690797</td>\n",
       "      <td>12680</td>\n",
       "      <td>0.106365</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16859</th>\n",
       "      <td>121</td>\n",
       "      <td>0.167783</td>\n",
       "      <td>16854</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16860</th>\n",
       "      <td>10585</td>\n",
       "      <td>0.167766</td>\n",
       "      <td>16857</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16861</th>\n",
       "      <td>6978</td>\n",
       "      <td>0.167763</td>\n",
       "      <td>16858</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16862</th>\n",
       "      <td>1862</td>\n",
       "      <td>0.167750</td>\n",
       "      <td>16860</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16863</th>\n",
       "      <td>16301</td>\n",
       "      <td>0.167748</td>\n",
       "      <td>16863</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16864 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       LDA_index  Distance  COS_index     Score\n",
       "0           8051  0.780022       8051  0.259877\n",
       "1           8052  0.774157       8052  0.191389\n",
       "2           9656  0.756458       2873  0.141748\n",
       "3           2873  0.723737       2874  0.106612\n",
       "4          16720  0.690797      12680  0.106365\n",
       "...          ...       ...        ...       ...\n",
       "16859        121  0.167783      16854  0.000000\n",
       "16860      10585  0.167766      16857  0.000000\n",
       "16861       6978  0.167763      16858  0.000000\n",
       "16862       1862  0.167750      16860  0.000000\n",
       "16863      16301  0.167748      16863  0.000000\n",
       "\n",
       "[16864 rows x 4 columns]"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 1-the lda score to make it comparable with cosine similarity\n",
    "lda_score_inv=[1-x for x in lda_score]\n",
    "lda_score_inv_df=pd.DataFrame(sorted(list(enumerate(lda_score_inv)), key=lambda x:x[1], reverse=True)[1:], \n",
    "                              columns=['LDA_index', 'Distance'])\n",
    "mix_df2=pd.concat([lda_score_inv_df, cos_score_df], axis=1)\n",
    "mix_df2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Wonder Woman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>wr</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>Justice League</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.098627</td>\n",
       "      <td>68.709270</td>\n",
       "      <td>71.0</td>\n",
       "      <td>127743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15947</th>\n",
       "      <td>Unstoppable</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.089906</td>\n",
       "      <td>69.057419</td>\n",
       "      <td>72.0</td>\n",
       "      <td>104686.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13088</th>\n",
       "      <td>Star Trek</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.056687</td>\n",
       "      <td>89.383976</td>\n",
       "      <td>91.0</td>\n",
       "      <td>747806.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1202</th>\n",
       "      <td>10 Cloverfield Lane</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.059745</td>\n",
       "      <td>71.886220</td>\n",
       "      <td>79.0</td>\n",
       "      <td>60918.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13095</th>\n",
       "      <td>Star Trek Into Darkness</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.052545</td>\n",
       "      <td>85.663820</td>\n",
       "      <td>89.0</td>\n",
       "      <td>312836.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16826</th>\n",
       "      <td>Z For Zachariah</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.102695</td>\n",
       "      <td>59.619928</td>\n",
       "      <td>45.0</td>\n",
       "      <td>7525.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13089</th>\n",
       "      <td>Star Trek Beyond</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.055600</td>\n",
       "      <td>73.329395</td>\n",
       "      <td>80.0</td>\n",
       "      <td>74549.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11146</th>\n",
       "      <td>People Like Us</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.069095</td>\n",
       "      <td>62.060112</td>\n",
       "      <td>62.0</td>\n",
       "      <td>31935.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15410</th>\n",
       "      <td>This Means War</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.066061</td>\n",
       "      <td>58.016938</td>\n",
       "      <td>56.0</td>\n",
       "      <td>89752.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8136</th>\n",
       "      <td>Jack Ryan: Shadow Recruit</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.055554</td>\n",
       "      <td>56.697266</td>\n",
       "      <td>53.0</td>\n",
       "      <td>64773.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     movie_title  year     Score         wr  audience_rating  \\\n",
       "8417              Justice League  2017  0.098627  68.709270             71.0   \n",
       "15947                Unstoppable  2010  0.089906  69.057419             72.0   \n",
       "13088                  Star Trek  2009  0.056687  89.383976             91.0   \n",
       "1202         10 Cloverfield Lane  2016  0.059745  71.886220             79.0   \n",
       "13095    Star Trek Into Darkness  2013  0.052545  85.663820             89.0   \n",
       "16826            Z For Zachariah  2015  0.102695  59.619928             45.0   \n",
       "13089           Star Trek Beyond  2016  0.055600  73.329395             80.0   \n",
       "11146             People Like Us  2012  0.069095  62.060112             62.0   \n",
       "15410             This Means War  2012  0.066061  58.016938             56.0   \n",
       "8136   Jack Ryan: Shadow Recruit  2014  0.055554  56.697266             53.0   \n",
       "\n",
       "       audience_count  \n",
       "8417         127743.0  \n",
       "15947        104686.0  \n",
       "13088        747806.0  \n",
       "1202          60918.0  \n",
       "13095        312836.0  \n",
       "16826          7525.0  \n",
       "13089         74549.0  \n",
       "11146         31935.0  \n",
       "15410         89752.0  \n",
       "8136          64773.0  "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#For comparing\n",
    "get_recommendations('Wonder Woman', cosine_sim_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Only sum up the cosine similarity score and lda distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>Iron Man 3</td>\n",
       "      <td>Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Robert Downey Jr., Chris Evans, Mark Ruffalo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>Marvel's The Avengers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>Robert Downey Jr., Mark Ruffalo, Scarlett Joha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>Chris Evans, Robert Downey Jr., Scarlett Johan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>Robert Downey Jr., Chris Hemsworth, Mark Ruffa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16720</th>\n",
       "      <td>X-Men: Days of Future Past</td>\n",
       "      <td>Hugh Jackman, James McAvoy, Michael Fassbender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>Spider-Man: Homecoming</td>\n",
       "      <td>Tom Holland (II), Michael Keaton, Robert Downe...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_title  \\\n",
       "8051                   Iron Man 2   \n",
       "8052                   Iron Man 3   \n",
       "2873      Avengers: Age of Ultron   \n",
       "9656        Marvel's The Avengers   \n",
       "2874            Avengers: Endgame   \n",
       "4069   Captain America: Civil War   \n",
       "2875       Avengers: Infinity War   \n",
       "16720  X-Men: Days of Future Past   \n",
       "13002      Spider-Man: Homecoming   \n",
       "\n",
       "                                                  actors  \n",
       "8051   Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...  \n",
       "8052   Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...  \n",
       "2873   Robert Downey Jr., Chris Evans, Mark Ruffalo, ...  \n",
       "9656                                                      \n",
       "2874   Robert Downey Jr., Mark Ruffalo, Scarlett Joha...  \n",
       "4069   Chris Evans, Robert Downey Jr., Scarlett Johan...  \n",
       "2875   Robert Downey Jr., Chris Hemsworth, Mark Ruffa...  \n",
       "16720  Hugh Jackman, James McAvoy, Michael Fassbender...  \n",
       "13002  Tom Holland (II), Michael Keaton, Robert Downe...  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sum_rank=sorted(list(enumerate((lda_score_inv+cosine_sim_all[idx]))), key=lambda x:x[1], reverse=True)\n",
    "sum_movie_indices = [i[0] for i in sum_rank]\n",
    "df_new.iloc[sum_movie_indices[1:10]][['movie_title','actors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rotten_tomatoes_link</th>\n",
       "      <th>lemmatized</th>\n",
       "      <th>review_count</th>\n",
       "      <th>freshness</th>\n",
       "      <th>words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8054</th>\n",
       "      <td>m/iron_man</td>\n",
       "      <td>[iron, man, actually, get, away, whole, film, ...</td>\n",
       "      <td>279</td>\n",
       "      <td>93.548387</td>\n",
       "      <td>4003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8055</th>\n",
       "      <td>m/iron_man_2</td>\n",
       "      <td>[sequel, go, one, acceptable, nothing, nothing...</td>\n",
       "      <td>297</td>\n",
       "      <td>72.053872</td>\n",
       "      <td>3926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8056</th>\n",
       "      <td>m/iron_man_3</td>\n",
       "      <td>[black, instinctive, feel, balance, action, se...</td>\n",
       "      <td>324</td>\n",
       "      <td>79.320988</td>\n",
       "      <td>4285</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2877</th>\n",
       "      <td>m/avengers_age_of_ultron</td>\n",
       "      <td>[stake, line, action, adventure, sky, high, so...</td>\n",
       "      <td>367</td>\n",
       "      <td>75.749319</td>\n",
       "      <td>5156</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9660</th>\n",
       "      <td>m/marvels_the_avengers</td>\n",
       "      <td>[emotional, involvement, good, sci, fi, action...</td>\n",
       "      <td>355</td>\n",
       "      <td>91.549296</td>\n",
       "      <td>4579</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16722</th>\n",
       "      <td>m/x2_xmen_united</td>\n",
       "      <td>[may, sound, fine, dandy, make, busy, film, ev...</td>\n",
       "      <td>244</td>\n",
       "      <td>85.245902</td>\n",
       "      <td>2651</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16726</th>\n",
       "      <td>m/x_men_days_of_future_past</td>\n",
       "      <td>[well, complete, entertaining, man, movie, eve...</td>\n",
       "      <td>327</td>\n",
       "      <td>90.214067</td>\n",
       "      <td>4516</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4074</th>\n",
       "      <td>m/captain_america_the_first_avenger</td>\n",
       "      <td>[yet, another, superhero, pic, one, nicely, ro...</td>\n",
       "      <td>268</td>\n",
       "      <td>79.850746</td>\n",
       "      <td>3697</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16734</th>\n",
       "      <td>m/xmen</td>\n",
       "      <td>[perfect, unique, big, budget, comic, book, mo...</td>\n",
       "      <td>167</td>\n",
       "      <td>80.838323</td>\n",
       "      <td>1621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15429</th>\n",
       "      <td>m/thor</td>\n",
       "      <td>[kenneth, branagh, thor, may, achieve, level, ...</td>\n",
       "      <td>286</td>\n",
       "      <td>76.923077</td>\n",
       "      <td>3683</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      rotten_tomatoes_link  \\\n",
       "8054                            m/iron_man   \n",
       "8055                          m/iron_man_2   \n",
       "8056                          m/iron_man_3   \n",
       "2877              m/avengers_age_of_ultron   \n",
       "9660                m/marvels_the_avengers   \n",
       "16722                     m/x2_xmen_united   \n",
       "16726          m/x_men_days_of_future_past   \n",
       "4074   m/captain_america_the_first_avenger   \n",
       "16734                               m/xmen   \n",
       "15429                               m/thor   \n",
       "\n",
       "                                              lemmatized  review_count  \\\n",
       "8054   [iron, man, actually, get, away, whole, film, ...           279   \n",
       "8055   [sequel, go, one, acceptable, nothing, nothing...           297   \n",
       "8056   [black, instinctive, feel, balance, action, se...           324   \n",
       "2877   [stake, line, action, adventure, sky, high, so...           367   \n",
       "9660   [emotional, involvement, good, sci, fi, action...           355   \n",
       "16722  [may, sound, fine, dandy, make, busy, film, ev...           244   \n",
       "16726  [well, complete, entertaining, man, movie, eve...           327   \n",
       "4074   [yet, another, superhero, pic, one, nicely, ro...           268   \n",
       "16734  [perfect, unique, big, budget, comic, book, mo...           167   \n",
       "15429  [kenneth, branagh, thor, may, achieve, level, ...           286   \n",
       "\n",
       "       freshness  words  \n",
       "8054   93.548387   4003  \n",
       "8055   72.053872   3926  \n",
       "8056   79.320988   4285  \n",
       "2877   75.749319   5156  \n",
       "9660   91.549296   4579  \n",
       "16722  85.245902   2651  \n",
       "16726  90.214067   4516  \n",
       "4074   79.850746   3697  \n",
       "16734  80.838323   1621  \n",
       "15429  76.923077   3683  "
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Only using the review\n",
    "recommend('iron_man',10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding weights on two scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "weight=0.4\n",
    "weight_score=zip([weight*x for x in lda_score_inv],[(1-weight)*y for y in cosine_sim_all[idx]])\n",
    "weighted_score=[x+y for x,y in weight_score]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>actors</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8051</th>\n",
       "      <td>Iron Man 2</td>\n",
       "      <td>Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8052</th>\n",
       "      <td>Iron Man 3</td>\n",
       "      <td>Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2873</th>\n",
       "      <td>Avengers: Age of Ultron</td>\n",
       "      <td>Robert Downey Jr., Chris Evans, Mark Ruffalo, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>Marvel's The Avengers</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>Robert Downey Jr., Mark Ruffalo, Scarlett Joha...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4069</th>\n",
       "      <td>Captain America: Civil War</td>\n",
       "      <td>Chris Evans, Robert Downey Jr., Scarlett Johan...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13002</th>\n",
       "      <td>Spider-Man: Homecoming</td>\n",
       "      <td>Tom Holland (II), Michael Keaton, Robert Downe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2875</th>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>Robert Downey Jr., Chris Hemsworth, Mark Ruffa...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16720</th>\n",
       "      <td>X-Men: Days of Future Past</td>\n",
       "      <td>Hugh Jackman, James McAvoy, Michael Fassbender...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13007</th>\n",
       "      <td>Spider-Man 3</td>\n",
       "      <td>Tobey Maguire, Kirsten Dunst, James Franco, Th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_title  \\\n",
       "8051                   Iron Man 2   \n",
       "8052                   Iron Man 3   \n",
       "2873      Avengers: Age of Ultron   \n",
       "9656        Marvel's The Avengers   \n",
       "2874            Avengers: Endgame   \n",
       "4069   Captain America: Civil War   \n",
       "13002      Spider-Man: Homecoming   \n",
       "2875       Avengers: Infinity War   \n",
       "16720  X-Men: Days of Future Past   \n",
       "13007                Spider-Man 3   \n",
       "\n",
       "                                                  actors  \n",
       "8051   Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...  \n",
       "8052   Robert Downey Jr., Gwyneth Paltrow, Don Cheadl...  \n",
       "2873   Robert Downey Jr., Chris Evans, Mark Ruffalo, ...  \n",
       "9656                                                      \n",
       "2874   Robert Downey Jr., Mark Ruffalo, Scarlett Joha...  \n",
       "4069   Chris Evans, Robert Downey Jr., Scarlett Johan...  \n",
       "13002  Tom Holland (II), Michael Keaton, Robert Downe...  \n",
       "2875   Robert Downey Jr., Chris Hemsworth, Mark Ruffa...  \n",
       "16720  Hugh Jackman, James McAvoy, Michael Fassbender...  \n",
       "13007  Tobey Maguire, Kirsten Dunst, James Franco, Th...  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weight_rank=sorted(list(enumerate(weighted_score)), key=lambda x:x[1], reverse=True)[1:]\n",
    "weight_movie_indices = [i[0] for i in weight_rank]\n",
    "df_new.iloc[weight_movie_indices[0:10]][['movie_title','actors']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "def combine_score_rating(target_idx, movie_indices, sim_scores):\n",
    "    \n",
    "    movie_content_rating=df_new.iloc[target_idx]['content_rating']  \n",
    "    movie_year=df_new.iloc[target_idx]['year']\n",
    "    \n",
    "    selected_movies=df_new.iloc[movie_indices]\n",
    "    audience_counts = selected_movies[selected_movies['audience_count'].notnull()]['audience_count'].astype('int')\n",
    "    \n",
    "    m = audience_counts.quantile(0.6)\n",
    "\n",
    "    C=selected_movies['audience_rating'].mean()\n",
    "    wr=selected_movies.apply(lambda x: weighted_rating(x,m,C), axis=1)\n",
    "\n",
    "    df=pd.DataFrame(df_new[['movie_title','content_rating','year','audience_rating','audience_count']].iloc[movie_indices])\n",
    "    df['Score']=[x[1] for x in sim_scores]\n",
    "    df['wr']=wr\n",
    "    #Product for similarity and rating so priortise to recommend high similarity and high rating movies\n",
    "    \n",
    "    df['mix_score']=df['wr']*df['Score']\n",
    "    \n",
    "    \n",
    "    #Set the limit for number of audience count\n",
    "    #At least higher than 50% quantile of the audience count in the whole document\n",
    "    count_bound=df_new['audience_count'].quantile(0.5)\n",
    "    #Remove movie that is over the target movie content rating and with too few audience\n",
    "    #ranked by the mix score\n",
    "    #Only select movie that is too old compared with the target movie, threshold is a decade-10 years.\n",
    "    df=df[(df['content_rating']<=movie_content_rating) & (df['audience_count']>count_bound) & (df['year']>movie_year-10)]\n",
    "    df=df.sort_values('mix_score', ascending=False)\n",
    "\n",
    "    # Return the top 10 most similar movies\n",
    "    return df[['movie_title','year','Score','audience_rating', 'audience_count']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend2(title, cosine_sim,weight=0.5, n=6):\n",
    "    \n",
    "    movie_list = df_new[df_new['movie_title'].str.contains(title)]\n",
    "    if len(movie_list):\n",
    "        #In case of similar movie title like 'Iron Man' and 'Iron Man 2'\n",
    "        if any(movie_list['movie_title']==title):\n",
    "            movie_title=title\n",
    "        else:\n",
    "           # Pick the one with the highest audience rating\n",
    "            movie_title=movie_list.sort_values(by=['audience_rating'], ascending=False)['movie_title'].iloc[0]\n",
    "        \n",
    "        print('Selected movie:',movie_title)\n",
    "    \n",
    "        #Some movies are duplicated such as Frozen has two version.\n",
    "        #Pick the one with higher audience rating\n",
    "        idx = indices[movie_title]\n",
    "        if np.isscalar(idx)==False:\n",
    "            idx=df_new.iloc[idx].sort_values(by=['audience_rating'], ascending=False).index[0]\n",
    "\n",
    "          \n",
    "        \n",
    "        test_bow2 = dictionary2.doc2bow(df_new.loc[idx]['lemmatized'])\n",
    "\n",
    "        test_doc_distribution2 = np.array([tup[1] for tup in lda2.get_document_topics(bow=test_bow2)])\n",
    "        lda_score=jensen_shannon(test_doc_distribution2,doc_topic_dist2)\n",
    "        lda_score_inv=[1-x for x in lda_score]\n",
    "\n",
    "        weight_score=zip([weight*x for x in lda_score_inv],[(1-weight)*y for y in cosine_sim[idx]])\n",
    "        weighted_score=[x+y for x,y in weight_score]\n",
    "        weight_rank=sorted(list(enumerate(weighted_score)), key=lambda x:x[1], reverse=True)[1:]\n",
    "\n",
    "        weight_movie_indices = [i[0] for i in weight_rank]\n",
    "        \n",
    "        #Created another function for simplification\n",
    "        #Adding constraints to the  movie recommendation list\n",
    "        recommend=combine_score_rating(idx,weight_movie_indices, weight_rank)\n",
    "        \n",
    "        #recommend=df_new.iloc[weight_movie_indices]\n",
    "        #return df_new.iloc[weight_movie_indices[0:10]][['movie_title','actors','audience_rating']]\n",
    "        return recommend.head(n)\n",
    "    else:\n",
    "        print('No records in our database. Please check your input')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Captain Marvel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>wr</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>Marvel's The Avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.070653</td>\n",
       "      <td>90.744832</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1135962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>Spider-Man: Far From Home</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.067559</td>\n",
       "      <td>90.805877</td>\n",
       "      <td>95.0</td>\n",
       "      <td>69242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8101</th>\n",
       "      <td>It's Kind of a Funny Story</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.043967</td>\n",
       "      <td>64.427345</td>\n",
       "      <td>66.0</td>\n",
       "      <td>34122.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3360</th>\n",
       "      <td>Big Game</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.040471</td>\n",
       "      <td>46.224138</td>\n",
       "      <td>34.0</td>\n",
       "      <td>8975.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_title  year     Score         wr  audience_rating  \\\n",
       "9656        Marvel's The Avengers  2012  0.070653  90.744832             91.0   \n",
       "13001   Spider-Man: Far From Home  2019  0.067559  90.805877             95.0   \n",
       "8101   It's Kind of a Funny Story  2010  0.043967  64.427345             66.0   \n",
       "3360                     Big Game  2015  0.040471  46.224138             34.0   \n",
       "\n",
       "       audience_count  \n",
       "9656        1135962.0  \n",
       "13001         69242.0  \n",
       "8101          34122.0  \n",
       "3360           8975.0  "
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_recommendations('Captain Marvel', cosine_sim_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Inception\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>Interstellar</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.340554</td>\n",
       "      <td>86.0</td>\n",
       "      <td>175957.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12940</th>\n",
       "      <td>Source Code</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.320631</td>\n",
       "      <td>82.0</td>\n",
       "      <td>125552.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9923</th>\n",
       "      <td>Minority Report</td>\n",
       "      <td>2002</td>\n",
       "      <td>0.311819</td>\n",
       "      <td>80.0</td>\n",
       "      <td>481543.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9077</th>\n",
       "      <td>Limitless</td>\n",
       "      <td>2011</td>\n",
       "      <td>0.333149</td>\n",
       "      <td>74.0</td>\n",
       "      <td>108340.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12408</th>\n",
       "      <td>Serenity</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.252005</td>\n",
       "      <td>91.0</td>\n",
       "      <td>313208.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11460</th>\n",
       "      <td>Primer</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.296925</td>\n",
       "      <td>79.0</td>\n",
       "      <td>46477.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           movie_title  year     Score  audience_rating  audience_count\n",
       "7997      Interstellar  2014  0.340554             86.0        175957.0\n",
       "12940      Source Code  2011  0.320631             82.0        125552.0\n",
       "9923   Minority Report  2002  0.311819             80.0        481543.0\n",
       "9077         Limitless  2011  0.333149             74.0        108340.0\n",
       "12408         Serenity  2005  0.252005             91.0        313208.0\n",
       "11460           Primer  2004  0.296925             79.0         46477.0"
      ]
     },
     "execution_count": 139,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend2('Inception', cosine_sim_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Catch Me If You Can\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4942</th>\n",
       "      <td>Dave Chappelle: Sticks &amp; Stones</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.217577</td>\n",
       "      <td>99.0</td>\n",
       "      <td>40887.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10702</th>\n",
       "      <td>Ocean's Eleven</td>\n",
       "      <td>2001</td>\n",
       "      <td>0.250780</td>\n",
       "      <td>80.0</td>\n",
       "      <td>32601771.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6317</th>\n",
       "      <td>Forrest Gump</td>\n",
       "      <td>1994</td>\n",
       "      <td>0.206380</td>\n",
       "      <td>95.0</td>\n",
       "      <td>1244237.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12293</th>\n",
       "      <td>Schizopolis</td>\n",
       "      <td>1996</td>\n",
       "      <td>0.285157</td>\n",
       "      <td>81.0</td>\n",
       "      <td>4931.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12310</th>\n",
       "      <td>Scott Pilgrim vs. the World</td>\n",
       "      <td>2010</td>\n",
       "      <td>0.233880</td>\n",
       "      <td>84.0</td>\n",
       "      <td>141600.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9172</th>\n",
       "      <td>Logan Lucky</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.264394</td>\n",
       "      <td>76.0</td>\n",
       "      <td>27698.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3813</th>\n",
       "      <td>Bridge of Spies</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.224291</td>\n",
       "      <td>87.0</td>\n",
       "      <td>65466.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16861</th>\n",
       "      <td>Zootopia</td>\n",
       "      <td>2016</td>\n",
       "      <td>0.207249</td>\n",
       "      <td>92.0</td>\n",
       "      <td>101511.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2876</th>\n",
       "      <td>The Aviator</td>\n",
       "      <td>2004</td>\n",
       "      <td>0.236548</td>\n",
       "      <td>79.0</td>\n",
       "      <td>207578.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16187</th>\n",
       "      <td>Walk the Line</td>\n",
       "      <td>2005</td>\n",
       "      <td>0.203983</td>\n",
       "      <td>90.0</td>\n",
       "      <td>545629.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           movie_title  year     Score  audience_rating  \\\n",
       "4942   Dave Chappelle: Sticks & Stones  2019  0.217577             99.0   \n",
       "10702                   Ocean's Eleven  2001  0.250780             80.0   \n",
       "6317                      Forrest Gump  1994  0.206380             95.0   \n",
       "12293                      Schizopolis  1996  0.285157             81.0   \n",
       "12310      Scott Pilgrim vs. the World  2010  0.233880             84.0   \n",
       "9172                       Logan Lucky  2017  0.264394             76.0   \n",
       "3813                   Bridge of Spies  2015  0.224291             87.0   \n",
       "16861                         Zootopia  2016  0.207249             92.0   \n",
       "2876                       The Aviator  2004  0.236548             79.0   \n",
       "16187                    Walk the Line  2005  0.203983             90.0   \n",
       "\n",
       "       audience_count  \n",
       "4942          40887.0  \n",
       "10702      32601771.0  \n",
       "6317        1244237.0  \n",
       "12293          4931.0  \n",
       "12310        141600.0  \n",
       "9172          27698.0  \n",
       "3813          65466.0  \n",
       "16861        101511.0  \n",
       "2876         207578.0  \n",
       "16187        545629.0  "
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend2('Catch Me If You Can' ,0.5,10, cosine_sim_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "rotten_tomatoes_link                                m/pursuit_of_happyness\n",
       "lemmatized               [pursuit, happyness, speak, eloquently, anxiet...\n",
       "review_count                                                           174\n",
       "freshness                                                          67.2414\n",
       "words                                                                 2208\n",
       "movie_title                                       The Pursuit of Happyness\n",
       "movie_info               Life is a struggle for single father Chris Gar...\n",
       "critics_consensus        Will Smith's heartfelt performance elevates Th...\n",
       "content_rating                                                           3\n",
       "genres                                                               Drama\n",
       "directors                                                 Gabriele Muccino\n",
       "authors                                    Steven Conrad, Gabriele Muccino\n",
       "actors                   Will Smith, Jaden Smith, Thandie Newton, Brian...\n",
       "original_release_date                                           2006-12-15\n",
       "production_company                                           Sony Pictures\n",
       "audience_rating                                                         87\n",
       "audience_count                                                      563450\n",
       "year                                                                  2006\n",
       "all_feature              Life is a struggle for single father Chris Gar...\n",
       "Name: 11560, dtype: object"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_new.iloc[indices['The Pursuit of Happyness']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Captain Marvel\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>13001</th>\n",
       "      <td>Spider-Man: Far From Home</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.354005</td>\n",
       "      <td>95.0</td>\n",
       "      <td>69242.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>Marvel's The Avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.351873</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1135962.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16720</th>\n",
       "      <td>X-Men: Days of Future Past</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.339873</td>\n",
       "      <td>91.0</td>\n",
       "      <td>277110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2874</th>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>2019</td>\n",
       "      <td>0.346505</td>\n",
       "      <td>90.0</td>\n",
       "      <td>70334.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.317435</td>\n",
       "      <td>92.0</td>\n",
       "      <td>255582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2686</th>\n",
       "      <td>Ant-Man</td>\n",
       "      <td>2015</td>\n",
       "      <td>0.329066</td>\n",
       "      <td>86.0</td>\n",
       "      <td>166901.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_title  year     Score  audience_rating  \\\n",
       "13001   Spider-Man: Far From Home  2019  0.354005             95.0   \n",
       "9656        Marvel's The Avengers  2012  0.351873             91.0   \n",
       "16720  X-Men: Days of Future Past  2014  0.339873             91.0   \n",
       "2874            Avengers: Endgame  2019  0.346505             90.0   \n",
       "6987      Guardians of the Galaxy  2014  0.317435             92.0   \n",
       "2686                      Ant-Man  2015  0.329066             86.0   \n",
       "\n",
       "       audience_count  \n",
       "13001         69242.0  \n",
       "9656        1135962.0  \n",
       "16720        277110.0  \n",
       "2874          70334.0  \n",
       "6987         255582.0  \n",
       "2686         166901.0  "
      ]
     },
     "execution_count": 142,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend2('Captain Marvel' ,cosine_sim_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Selected movie: Wonder Woman\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>movie_title</th>\n",
       "      <th>year</th>\n",
       "      <th>Score</th>\n",
       "      <th>audience_rating</th>\n",
       "      <th>audience_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>8417</th>\n",
       "      <td>Justice League</td>\n",
       "      <td>2017</td>\n",
       "      <td>0.341681</td>\n",
       "      <td>71.0</td>\n",
       "      <td>127743.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13376</th>\n",
       "      <td>Man of Steel</td>\n",
       "      <td>2013</td>\n",
       "      <td>0.313933</td>\n",
       "      <td>75.0</td>\n",
       "      <td>448951.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16660</th>\n",
       "      <td>Wonder Woman</td>\n",
       "      <td>2009</td>\n",
       "      <td>0.317992</td>\n",
       "      <td>78.0</td>\n",
       "      <td>8565.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16720</th>\n",
       "      <td>X-Men: Days of Future Past</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.213063</td>\n",
       "      <td>91.0</td>\n",
       "      <td>277110.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6987</th>\n",
       "      <td>Guardians of the Galaxy</td>\n",
       "      <td>2014</td>\n",
       "      <td>0.203739</td>\n",
       "      <td>92.0</td>\n",
       "      <td>255582.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9656</th>\n",
       "      <td>Marvel's The Avengers</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.196959</td>\n",
       "      <td>91.0</td>\n",
       "      <td>1135962.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                      movie_title  year     Score  audience_rating  \\\n",
       "8417               Justice League  2017  0.341681             71.0   \n",
       "13376                Man of Steel  2013  0.313933             75.0   \n",
       "16660                Wonder Woman  2009  0.317992             78.0   \n",
       "16720  X-Men: Days of Future Past  2014  0.213063             91.0   \n",
       "6987      Guardians of the Galaxy  2014  0.203739             92.0   \n",
       "9656        Marvel's The Avengers  2012  0.196959             91.0   \n",
       "\n",
       "       audience_count  \n",
       "8417         127743.0  \n",
       "13376        448951.0  \n",
       "16660          8565.0  \n",
       "16720        277110.0  \n",
       "6987         255582.0  \n",
       "9656        1135962.0  "
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "recommend2('Wonder Woman' ,0.5,6, cosine_sim_all)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
